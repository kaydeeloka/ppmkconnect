{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6358196,"sourceType":"datasetVersion","datasetId":3579787},{"sourceId":8575334,"sourceType":"datasetVersion","datasetId":5127760},{"sourceId":8171572,"sourceType":"datasetVersion","datasetId":4836275}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchaudio librosa\n\nimport os\nimport librosa\nimport numpy as np\nimport torch\nimport torchaudio\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom sklearn.model_selection import train_test_split\nfrom glob import glob\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T06:40:30.422714Z","iopub.execute_input":"2025-09-29T06:40:30.423357Z","iopub.status.idle":"2025-09-29T06:41:56.053374Z","shell.execute_reply.started":"2025-09-29T06:40:30.423330Z","shell.execute_reply":"2025-09-29T06:41:56.052426Z"},"_kg_hide-output":false},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\nRequirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchaudio)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchaudio)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchaudio)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchaudio)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchaudio)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchaudio)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\nRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.3->librosa) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.3->librosa) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.3->librosa) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"class FusionAudioDataset(Dataset):\n    def __init__(self, real_files, fake_files):\n        self.samples = [(f, 0) for f in real_files] + [(f, 1) for f in fake_files]\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        # Raw waveform\n        waveform, sr = torchaudio.load(path)\n        waveform = waveform[:, :16000]  # Truncate or pad to 1 sec\n        if waveform.shape[1] < 16000:\n            pad = 16000 - waveform.shape[1]\n            waveform = torch.nn.functional.pad(waveform, (0, pad))\n\n        # Mel spectrogram\n        mel = audio_to_mel(path)\n        mel = torch.tensor(mel).unsqueeze(0)\n\n        return waveform.float(), mel.float(), torch.tensor(label).long()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-29T06:41:56.054482Z","iopub.execute_input":"2025-09-29T06:41:56.054919Z","iopub.status.idle":"2025-09-29T06:41:56.062523Z","shell.execute_reply.started":"2025-09-29T06:41:56.054885Z","shell.execute_reply":"2025-09-29T06:41:56.062018Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchaudio\nimport librosa\nimport numpy as np\n\nclass DeepfakeAudioDataset(Dataset):\n    def __init__(self, root_dir, sample_rate=16000, duration=1.0):\n        self.root_dir = root_dir\n        self.sample_rate = sample_rate\n        self.duration = duration\n        self.audio_paths = []\n        self.labels = []\n\n        # change the label based on the file name.\n        for label_str, label in [('real', 0), ('fake', 1)]:\n            folder = os.path.join(root_dir, label_str)\n            for file in os.listdir(folder):\n                #follow what the file format\n                if file.endswith(\".wav\"):\n                    self.audio_paths.append(os.path.join(folder, file))\n                    self.labels.append(label)\n\n    def __len__(self):\n        return len(self.audio_paths)\n\n    def __getitem__(self, idx):\n        path = self.audio_paths[idx]\n        label = self.labels[idx]\n\n        waveform, sr = torchaudio.load(path)\n        waveform = waveform.mean(dim=0)  # mono\n        waveform = torchaudio.functional.resample(waveform, sr, self.sample_rate)\n\n        # Pad/crop to fixed duration\n        max_len = int(self.sample_rate * self.duration)\n        if waveform.shape[0] < max_len:\n            waveform = torch.nn.functional.pad(waveform, (0, max_len - waveform.shape[0]))\n        else:\n            waveform = waveform[:max_len]\n\n        # Mel spectrogram\n        mel = librosa.feature.melspectrogram(y=waveform.numpy(), sr=self.sample_rate, n_mels=128)\n        mel_db = librosa.power_to_db(mel, ref=np.max)\n        mel_tensor = torch.tensor(mel_db).unsqueeze(0).float()  # (1, 128, T)\n\n        return waveform.unsqueeze(0).float(), mel_tensor, torch.tensor(label).long()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T06:41:56.064143Z","iopub.execute_input":"2025-09-29T06:41:56.064352Z","iopub.status.idle":"2025-09-29T06:41:56.079988Z","shell.execute_reply.started":"2025-09-29T06:41:56.064337Z","shell.execute_reply":"2025-09-29T06:41:56.079369Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class SpecRNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d((32, 32))\n        )\n        self.fc = nn.Linear(64 * 32 * 32, 128)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        return self.fc(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T06:41:56.080662Z","iopub.execute_input":"2025-09-29T06:41:56.081001Z","iopub.status.idle":"2025-09-29T06:41:56.094261Z","shell.execute_reply.started":"2025-09-29T06:41:56.080896Z","shell.execute_reply":"2025-09-29T06:41:56.093626Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class RawGATST(nn.Module):\n    def __init__(self):\n        super(RawGATST, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv1d(1, 64, kernel_size=5, stride=2, padding=2),\n            nn.BatchNorm1d(64), nn.ReLU(),\n            nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2),\n            nn.BatchNorm1d(128), nn.ReLU()\n        )\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.fc = nn.Linear(128, 128)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.pool(x).squeeze(-1)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T06:41:56.095008Z","iopub.execute_input":"2025-09-29T06:41:56.095221Z","iopub.status.idle":"2025-09-29T06:41:56.107356Z","shell.execute_reply.started":"2025-09-29T06:41:56.095206Z","shell.execute_reply":"2025-09-29T06:41:56.106807Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class FusionNet(nn.Module):\n    def __init__(self):\n        super(FusionNet, self).__init__()\n        self.spec_model = SpecRNet()\n        self.raw_model = RawGATST()\n        self.classifier = nn.Sequential(\n            nn.Linear(128 + 128, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 2)\n        )\n\n    def forward(self, raw_wave, mel_spec):\n        raw_feat = self.raw_model(raw_wave)\n        spec_feat = self.spec_model(mel_spec)\n        fused = torch.cat((raw_feat, spec_feat), dim=1)\n        return self.classifier(fused)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T06:41:56.107944Z","iopub.execute_input":"2025-09-29T06:41:56.108184Z","iopub.status.idle":"2025-09-29T06:41:56.119308Z","shell.execute_reply.started":"2025-09-29T06:41:56.108152Z","shell.execute_reply":"2025-09-29T06:41:56.118681Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from torch.utils.data import Subset\nfrom sklearn.model_selection import train_test_split\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Get dataset\ndataset = DeepfakeAudioDataset(\"/kaggle/input/in-the-wild-audio-deepfake/release_in_the_wild\")\n\n# Create index list\nindices = list(range(len(dataset)))\n\n# Split into train + temp (val+test)\ntrain_idx, temp_idx = train_test_split(indices, test_size=0.4, random_state=42)  # 60% train, 40% temp\n\n# Split temp into validation + test (each 20%)\nval_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)  # 20% val, 20% test\n\n# Wrap subsets\ntrain_set = Subset(dataset, train_idx)\nval_set   = Subset(dataset, val_idx)\ntest_set  = Subset(dataset, test_idx)\n\n# DataLoaders\ntrain_loader = DataLoader(train_set, batch_size=8, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_set, batch_size=8, shuffle=True, num_workers=2)\ntest_loader  = DataLoader(test_set, batch_size=8, shuffle=True, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T06:41:56.119953Z","iopub.execute_input":"2025-09-29T06:41:56.120106Z","iopub.status.idle":"2025-09-29T06:41:56.525182Z","shell.execute_reply.started":"2025-09-29T06:41:56.120094Z","shell.execute_reply":"2025-09-29T06:41:56.524359Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = FusionNet().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nloss_fn = nn.CrossEntropyLoss()\n\n# Training loop\nfor epoch in range(20):\n    model.train()\n    total_loss = 0\n    correct = 0\n    for raw, mel, labels in train_loader:\n        raw, mel, labels = raw.to(device), mel.to(device), labels.to(device)\n        optimizer.zero_grad()\n        output = model(raw, mel)\n        loss = loss_fn(output, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        correct += (output.argmax(1) == labels).sum().item()\n    acc = correct / len(train_loader.dataset)\n    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Train Acc: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T06:41:56.526037Z","iopub.execute_input":"2025-09-29T06:41:56.526290Z","iopub.status.idle":"2025-09-29T07:20:57.844604Z","shell.execute_reply.started":"2025-09-29T06:41:56.526272Z","shell.execute_reply":"2025-09-29T07:20:57.843754Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 501.4216, Train Acc: 0.9413\nEpoch 2, Loss: 112.8951, Train Acc: 0.9858\nEpoch 3, Loss: 80.1846, Train Acc: 0.9890\nEpoch 4, Loss: 56.1395, Train Acc: 0.9927\nEpoch 5, Loss: 41.3158, Train Acc: 0.9951\nEpoch 6, Loss: 38.1364, Train Acc: 0.9950\nEpoch 7, Loss: 31.1283, Train Acc: 0.9961\nEpoch 8, Loss: 27.8921, Train Acc: 0.9972\nEpoch 9, Loss: 26.5467, Train Acc: 0.9969\nEpoch 10, Loss: 20.7419, Train Acc: 0.9973\nEpoch 11, Loss: 22.1530, Train Acc: 0.9974\nEpoch 12, Loss: 19.7598, Train Acc: 0.9973\nEpoch 13, Loss: 11.6636, Train Acc: 0.9983\nEpoch 14, Loss: 15.2707, Train Acc: 0.9982\nEpoch 15, Loss: 15.0848, Train Acc: 0.9982\nEpoch 16, Loss: 12.6915, Train Acc: 0.9985\nEpoch 17, Loss: 15.1656, Train Acc: 0.9983\nEpoch 18, Loss: 8.1618, Train Acc: 0.9991\nEpoch 19, Loss: 18.5750, Train Acc: 0.9980\nEpoch 20, Loss: 16.3234, Train Acc: 0.9983\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"torch.save(model.state_dict(), \"specRNet_rawGATST_fusion_adam_fulldataset_deep-voice-recog.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T07:20:57.847517Z","iopub.execute_input":"2025-09-29T07:20:57.847875Z","iopub.status.idle":"2025-09-29T07:20:57.934973Z","shell.execute_reply.started":"2025-09-29T07:20:57.847852Z","shell.execute_reply":"2025-09-29T07:20:57.934205Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"#save checkpoint model state \n\n#tukar nama model everytime tukar nama model or anything.. baca paper","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\nmodel.eval()\n\nmisclassified = []\ncorrect_pred = []\n\nwith torch.no_grad():\n    for raw_batch, mel_batch, labels_batch in test_loader:\n        raw_batch, mel_batch, labels_batch = raw_batch.to(device), mel_batch.to(device), labels_batch.to(device)\n\n        outputs = model(raw_batch, mel_batch)\n        probs = F.softmax(outputs, dim=1)\n        preds = torch.argmax(probs, dim=1)\n\n        for i in range(len(labels_batch)):\n            true_label = labels_batch[i].item()\n            pred_label = preds[i].item()\n            confidence = probs[i][pred_label].item()\n\n            entry = {\n                \"true\": \"FAKE\" if true_label == 1 else \"REAL\",\n                \"pred\": \"FAKE\" if pred_label == 1 else \"REAL\",\n                \"confidence\": confidence\n            }\n\n            if true_label != pred_label:\n                misclassified.append(entry)\n            else:\n                correct_pred.append(entry)\n\nprint(f\"âœ… Total Correct: {len(correct_pred)}\")\nprint(f\"âŒ Total Misclassified: {len(misclassified)}\")\n\n# Show some misclassifications\nprint(\"\\nğŸ” Sample Misclassifications:\")\nfor item in misclassified[:10]:  # show first 10\n    print(f\"True={item['true']} | Pred={item['pred']} | Conf={item['confidence']*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T07:20:57.935821Z","iopub.execute_input":"2025-09-29T07:20:57.936074Z","iopub.status.idle":"2025-09-29T07:22:09.372448Z","shell.execute_reply.started":"2025-09-29T07:20:57.936051Z","shell.execute_reply":"2025-09-29T07:22:09.371737Z"}},"outputs":[{"name":"stdout","text":"âœ… Total Correct: 6314\nâŒ Total Misclassified: 42\n\nğŸ” Sample Misclassifications:\nTrue=FAKE | Pred=REAL | Conf=100.00%\nTrue=FAKE | Pred=REAL | Conf=96.51%\nTrue=REAL | Pred=FAKE | Conf=99.82%\nTrue=FAKE | Pred=REAL | Conf=99.75%\nTrue=FAKE | Pred=REAL | Conf=99.85%\nTrue=REAL | Pred=FAKE | Conf=71.97%\nTrue=REAL | Pred=FAKE | Conf=100.00%\nTrue=FAKE | Pred=REAL | Conf=99.76%\nTrue=FAKE | Pred=REAL | Conf=85.55%\nTrue=REAL | Pred=FAKE | Conf=97.57%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import time\nimport torch.nn.functional as F\n\n# Move model to device (if not already)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Get one batch from the validation loader\ndata_iter = iter(test_loader)\nraw_batch, mel_batch, labels_batch = next(data_iter)\n\n# Pick one sample (e.g. index 0)\nraw_sample = raw_batch[2].unsqueeze(0).to(device)  # move to GPU\nmel_sample = mel_batch[2].unsqueeze(0).to(device)  # move to GPU\nlabel = labels_batch[2].item()\n\n# Start timing\nstart_time = time.time()\n\n# Run inference\nmodel.eval()\nwith torch.no_grad():\n    output = model(raw_sample, mel_sample)\n    prediction = torch.argmax(output, dim=1).item()\n    probs = F.softmax(output, dim=1)\n    confidence = probs[0][prediction].item()\n\nend_time = time.time()\ninference_time = end_time - start_time\n\n# Print results\nprint(f\"True Label: {'FAKE' if label == 1 else 'REAL'}\")\nprint(f\"Prediction: {'FAKE' if prediction == 1 else 'REAL'} ({confidence*100:.2f}%)\")\nprint(f\"Inference Time: {inference_time:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T07:22:09.373301Z","iopub.execute_input":"2025-09-29T07:22:09.373528Z","iopub.status.idle":"2025-09-29T07:22:10.844545Z","shell.execute_reply.started":"2025-09-29T07:22:09.373505Z","shell.execute_reply":"2025-09-29T07:22:10.843004Z"}},"outputs":[{"name":"stdout","text":"True Label: REAL\nPrediction: REAL (100.00%)\nInference Time: 0.0533 seconds\n","output_type":"stream"}],"execution_count":11}]}